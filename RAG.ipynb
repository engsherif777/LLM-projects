{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d272321-2189-4997-982d-1624e92d70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "import os \n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader , TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fd193d-4089-4da7-acdc-2895e31dcd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_dbl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865ab545-5d0a-43a9-8b42-4ce6049de89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360fd59e-27d4-4268-9e61-249cd6f6976d",
   "metadata": {},
   "source": [
    "# Preparing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f6ea36-22bc-496c-8f3e-443a56667337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks : 8\n",
      "Document types found: {'store policy', 'misc info', 'working hours', 'store location', 'top staff', 'store info'}\n"
     ]
    }
   ],
   "source": [
    "folders = glob.glob(\"Database/*\")\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "text_loader_kwargs = {'encoding':'utf-8'}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder,glob=\"**/*.md\",loader_cls = TextLoader, loader_kwargs= text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    documents.extend([add_metadata(doc,doc_type) for doc in folder_docs])\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of chunks : {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511d4cc-fd70-48fc-98f0-5a8d2cf257d5",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f666b4c4-9acf-4f57-b74f-c6ebc0b28eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 88\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings() \n",
    "\n",
    "if os.path.exists(db_name):  # checks for the existence of a directory or file named db_name\n",
    "    Chroma(persist_directory=db_name, embedding_function = embeddings)\n",
    "    # Chroma: A vector store implementation from langchain that uses Chroma to manage embeddings \n",
    "vectorstore = Chroma.from_documents(documents=chunks,embedding=embeddings,persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf8fa697-76a4-440b-8282-0569e482771f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 96\n"
     ]
    }
   ],
   "source": [
    "# creating a vector store\n",
    "vectorstore = Chroma.from_documents(documents= chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a681e1d-2913-4173-a7a0-edb9cfc9a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 96 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1,include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4fabf5-54b3-4afc-a2a0-dac4c31b256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/ghbhygn97p30c1z12nfn7np80000gn/T/ipykernel_48867/2290987020.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n",
    "\n",
    "#retrieving\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":25})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38336396-0f83-4fc6-88a7-f20cc0949e6e",
   "metadata": {},
   "source": [
    "# Rewrite-Retrieve-Read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4ee34-6606-420b-b58c-557e3bddd15a",
   "metadata": {},
   "source": [
    "this is a method we will use for query transformation Because the original query can not be always optimal to retrieve for the LLM, especially in the real world we first prompt an LLM to rewrite the queries, then conduct retrieval-augmented reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94307486-575a-4f28-acfe-62bb78c6a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Provide a better search query for \\\n",
    "web search engine to answer the given question,\n",
    "end \\\n",
    "the queries with '**'. Question: \\\n",
    "{x} Answer\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rewrite_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938c7270-7ef2-441e-b134-e20e9d747fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "rewrite_prompt = hub.pull(\"langchain-ai/rewrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56657b0c-9d6d-47e0-982b-eec9d0d6c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser to remove the '**'\n",
    "\n",
    "def _parse(text):\n",
    "    return text.strip('\"').strip(\"**\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae0fd50-b03e-4202-bf65-37d2af9211e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewriter = rewrite_prompt | ChatOpenAI(temperature=0.7) | StrOutputParser() | _parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2bdcc18-b05a-4884-8e0d-ec8507bb9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a distracted query to test the function we created\n",
    "distracted_query = \"life is weird and meaningless , who is the general manager?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e1cced-2f7a-4589-8651-2312a75f3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant. \n",
    "    Use the following context to answer the question.\n",
    "    Context: {context}\n",
    "    Question: {x}\n",
    "    Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b293811-992f-4e46-a845-2b14432a66f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general manager is Sarah Thompson.\n"
     ]
    }
   ],
   "source": [
    "reader = qa_prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "\n",
    "\n",
    "rag_chain = {\n",
    "    \"x\": RunnablePassthrough(),\n",
    "    \"context\": rewriter | retriever\n",
    "} | reader\n",
    "\n",
    "response = rag_chain.invoke(distracted_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25613f3a-3dc4-445d-a04e-3328fc5b3f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/ghbhygn97p30c1z12nfn7np80000gn/T/ipykernel_48867/4073289722.py:95: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Iterable\n",
    "import gradio as gr\n",
    "from gradio.themes.base import Base\n",
    "from gradio.themes.utils import colors, fonts, sizes\n",
    "import time\n",
    "\n",
    "# === Custom Theme ===\n",
    "class Seafoam(Base):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        primary_hue: colors.Color | str = colors.violet,\n",
    "        secondary_hue: colors.Color | str = colors.sky,\n",
    "        neutral_hue: colors.Color | str = colors.green,\n",
    "        spacing_size: sizes.Size | str = sizes.spacing_sm,\n",
    "        radius_size: sizes.Size | str = sizes.radius_lg,\n",
    "        text_size: sizes.Size | str = sizes.text_lg,\n",
    "        font: fonts.Font\n",
    "        | str\n",
    "        | Iterable[fonts.Font | str] = (\n",
    "            fonts.GoogleFont(\"Quicksand\"),\n",
    "            \"ui-sans-serif\",\n",
    "            \"sans-serif\",\n",
    "        ),\n",
    "        font_mono: fonts.Font\n",
    "        | str\n",
    "        | Iterable[fonts.Font | str] = (\n",
    "            fonts.GoogleFont(\"IBM Plex Mono\"),\n",
    "            \"ui-monospace\",\n",
    "            \"monospace\",\n",
    "        ),\n",
    "    ):\n",
    "        super().__init__(\n",
    "            primary_hue=primary_hue,\n",
    "            secondary_hue=secondary_hue,\n",
    "            neutral_hue=neutral_hue,\n",
    "            spacing_size=spacing_size,\n",
    "            radius_size=radius_size,\n",
    "            text_size=text_size,\n",
    "            font=font,\n",
    "            font_mono=font_mono,\n",
    "        )\n",
    "        super().set(\n",
    "            button_border_width=\"0px\",\n",
    "            checkbox_label_border_width=\"1px\",\n",
    "            button_transform_hover=\"scale(1.02)\",\n",
    "            button_transition=\"all 0.1s ease-in-out\",\n",
    "            slider_color=\"*primary_400\",\n",
    "            button_primary_background_fill=\"linear-gradient(120deg, *secondary_500 0%, *primary_300 60%, *primary_400 100%)\",\n",
    "            button_primary_background_fill_hover=\"linear-gradient(120deg, *secondary_400 0%, *primary_300 60%, *primary_300 100%)\",\n",
    "            button_primary_text_color=\"*button_secondary_text_color\",\n",
    "            button_secondary_background_fill=\"linear-gradient(120deg, *neutral_300 0%, *neutral_100 60%, *neutral_200 100%)\",\n",
    "            button_secondary_background_fill_hover=\"linear-gradient(120deg, *neutral_200 0%, *neutral_100 60%, *neutral_100 100%)\",\n",
    "            checkbox_label_background_fill_selected=\"linear-gradient(120deg, *primary_400 0%, *primary_300 60%, *primary_400 100%)\",\n",
    "            checkbox_label_border_color_selected=\"*primary_400\",\n",
    "            checkbox_background_color_selected=\"*primary_400\",\n",
    "            checkbox_label_text_color_selected=\"*button_secondary_text_color\",\n",
    "            slider_color_dark=\"*primary_500\",\n",
    "            button_primary_background_fill_dark=\"linear-gradient(120deg, *secondary_600 0%, *primary_500 60%, *primary_600 100%)\",\n",
    "            button_primary_background_fill_hover_dark=\"linear-gradient(120deg, *secondary_500 0%, *primary_500 60%, *primary_500 100%)\",\n",
    "            button_primary_text_color_dark=\"*button_secondary_text_color\",\n",
    "            button_secondary_background_fill_dark=\"linear-gradient(120deg, *neutral_700 0%, *neutral_600 60%, *neutral_700 100%)\",\n",
    "            button_secondary_background_fill_hover_dark=\"linear-gradient(120deg, *neutral_600 0%, *neutral_600 60%, *neutral_700 100%)\",\n",
    "            checkbox_label_background_fill_selected_dark=\"linear-gradient(120deg, *primary_600 0%, *primary_500 60%, *primary_600 100%)\",\n",
    "            checkbox_label_border_color_selected_dark=\"*primary_600\",\n",
    "            checkbox_background_color_selected_dark=\"*primary_600\",\n",
    "            checkbox_label_text_color_selected_dark=\"*button_secondary_text_color\",\n",
    "            block_shadow=\"*shadow_drop_lg\",\n",
    "            button_secondary_shadow_hover=\"*shadow_drop_lg\",\n",
    "            button_primary_shadow_hover=\"0 1px 3px 0 *primary_200, 0 1px 2px -1px *primary_200\",\n",
    "            button_secondary_shadow_dark=\"none\",\n",
    "            button_primary_shadow_dark=\"none\",\n",
    "        )\n",
    "\n",
    "seafoam = Seafoam()\n",
    "\n",
    "# === RAG Chat Function ===\n",
    "def chat(question, history):\n",
    "    try:\n",
    "        result = rag_chain.invoke({\"x\": question})\n",
    "        # if result is a string, return it directly\n",
    "        if isinstance(result, str):\n",
    "            return result\n",
    "        # if result is dict, pull out the answer\n",
    "        elif isinstance(result, dict):\n",
    "            return result.get(\"answer\", str(result))\n",
    "        else:\n",
    "            return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Error: {str(e)}\"\n",
    "# === Gradio Interface with Theme ===\n",
    "with gr.Blocks(theme=seafoam) as demo:\n",
    "    gr.Markdown(\"Aurora Home & Kitchen Chatbot\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(label=\"Ask me anything\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def respond(message, chat_history):\n",
    "        answer = chat(message, chat_history)\n",
    "        chat_history.append((message, answer))\n",
    "        return \"\", chat_history\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c9d8a72-e892-446e-99cc-0f1cce634dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%ai` not found.\n"
     ]
    }
   ],
   "source": [
    "%%ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ff737-5e87-4061-92a4-9d0938cd65f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
